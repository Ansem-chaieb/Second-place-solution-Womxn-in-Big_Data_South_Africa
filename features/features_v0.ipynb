{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from helper.utils import *\n",
    "from helper.cross_validation import *\n",
    "from config import *\n",
    "from helper.categorical_features import * \n",
    "from sklearn.cluster import KMeans\n",
    "import geopandas as gpd\n",
    "# %load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(join(raw_data_path,\"Train.csv\"))\n",
    "test = pd.read_csv(join(raw_data_path, \"Test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_columns=[\"NL\",\"lon\",\"lat\",\"total_households\",\"total_individuals\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove=[\"dw_12\",\"dw_13\",\"lan_13\",\"pw_07\",\"pw_08\"]\n",
    "train.drop(columns_to_remove,1,inplace=True)\n",
    "test.drop(columns_to_remove,1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_ratio=list(set([col.split(\"_\")[0] for col in test.columns if col not in other_columns+[\"ward\"] ]))\n",
    "# for prefix in columns_ratio : \n",
    "#     col_opp=[col for col in test.columns if col.startswith(prefix)]\n",
    "#     train[prefix+\"_mean\"]=train[col_opp].mean(axis=1)\n",
    "#     train[prefix+\"_std\"]=train[col_opp].std(axis=1)\n",
    "    \n",
    "# #     train[prefix+\"_min\"]=train[col_opp].min(axis=1)    \n",
    "# #     train[prefix+\"_max\"]=train[col_opp].max(axis=1)    \n",
    "# #     train[prefix+\"_median\"]=train[col_opp].median(axis=1)  \n",
    "    \n",
    "    \n",
    "#     test[prefix+\"_mean\"]=test[col_opp].mean(axis=1)\n",
    "#     test[prefix+\"_std\"]=test[col_opp].std(axis=1)\n",
    "    \n",
    "# #     test[prefix+\"_min\"]=test[col_opp].min(axis=1)    \n",
    "# #     test[prefix+\"_max\"]=test[col_opp].max(axis=1)    \n",
    "# #     test[prefix+\"_median\"]=test[col_opp].median(axis=1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"train\"]=1\n",
    "test[\"train\"]=0\n",
    "data=pd.concat([train,test])\n",
    "lat_lon=data[[\"lat\",\"lon\"]]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop=['dw_00','dw_02', 'dw_06','psa_02','lan_02','lan_03','lan_04',\n",
    "    'lan_05','lan_08', 'pw_01' , 'lan_07','NL',]\n",
    "data.drop(cols_to_drop,1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"ADM4_PCODE\"]=data[\"ADM4_PCODE\"].apply(lambda x:int(x.replace(\"ZA\",\"\")))\n",
    "# data[\"ward_num\"]=data.ward.apply(lambda x:x.split(\":\")[0])\n",
    "# data[\"ADM4_PCODE_part_1\"]=data[\"ADM4_PCODE\"].apply(lambda x:int( str(x)[0:5]))\n",
    "# data[\"ADM4_PCODE_part_2\"]=data[\"ADM4_PCODE\"].apply(lambda x: int(str(x)[-3:]))\n",
    "# data[\"ADM4_PCODE_part_1_1\"]=data[\"ADM4_PCODE_part_1\"].apply(lambda x: int(str(x)[0:3]))\n",
    "# data[\"ADM4_PCODE_part_1_2\"]=data[\"ADM4_PCODE_part_1\"].apply(lambda x: int(str(x)[-3:]))\n",
    "# for i in range(5) :\n",
    "#     data[\"ADM4_PCODE_part_1\"+str(i)]=data[\"ADM4_PCODE_part_1\"].apply(lambda x:int(str(x)[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sacled features \n",
    "# from sklearn.preprocessing import MinMaxScaler ,QuantileTransformer\n",
    "# columns=test.drop([\"ward\",\"train\"],1).columns\n",
    "# data[columns]=MinMaxScaler(output_distribution=\"normal\").fit_transform(data[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# km=KMeans(5,random_state=2019)\n",
    "# data[\"lat_lon_cluster\"]=km.fit_predict(lat_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# km=KMeans(10,random_state=2019)\n",
    "# columns_ratio=list(set([col.split(\"_\")[0] for col in test.columns if col not in other_columns+[\"ward\",\"train\"] ]))\n",
    "# last_columns=[]\n",
    "# for prefix in columns_ratio :\n",
    "#     col_opp=[col for col in test.columns if col.startswith(prefix)]\n",
    "#     data[\"km_\"+prefix]=km.fit_predict(data[col_opp])\n",
    "# #     data[\"km_\"+prefix]=km.fit_predict(data[last_columns])\n",
    "    \n",
    "#     last_columns.append(col_opp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"ratio_total_households\"]=data.total_households/data.total_households.sum()\n",
    "# data[\"ratio_total_individuals\"]=data.total_individuals/data.total_individuals.sum()\n",
    "# data[\"total_households/total_individuals\"]=data.total_households/data.total_individuals\n",
    "# data[\"city\"]=data[\"ward\"].apply(lambda x: str(x)[0:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rich'] = data['car_01']+data['stv_00']+data['psa_01']\n",
    "data['poor'] = data['car_00'] +data['stv_01']+data['psa_00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"sum_columns\"]=data[columns].sum(1)\n",
    "# for column in  columns :\n",
    "#     data[column]=data[column].round(2)\n",
    "#     .map(data[column].round(3).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=data.drop([\"ward\",\"target\",\"train\",\"ADM4_PCODE\"],1).columns\n",
    "\n",
    "data_km=data[columns].copy()\n",
    "data_km[\"total_households\"]/=data_km[\"total_households\"].max()\n",
    "data_km[\"total_individuals\"]/=data_km[\"total_individuals\"].max()\n",
    "\n",
    "km=KMeans(10,random_state=2019)\n",
    "data[\"cluster\"]=km.fit_predict(data_km[columns])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ward_area=pd.read_csv(join(proc_data_path,\"ward_area.csv\"))\n",
    "ward_area[\"ADM4_PCODE\"]=ward_area[\"ADM4_PCODE\"].apply(lambda x:int(x.replace(\"ZA\",\"\")))\n",
    "data=data.merge(ward_area,how=\"left\",on=[\"ADM4_PCODE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=data[data.train==1].reset_index(drop=True)\n",
    "test=data[data.train==0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = cross_validation(\n",
    "    train_df=train,\n",
    "    _id_=\"ward\",\n",
    "    target_name=\"target\",\n",
    "    kfold_type=\"kfold\",\n",
    "    output_dir=proc_data_path,\n",
    "    split_ratio=0.1,\n",
    "    nfolds=10,\n",
    "    random_state=1994,\n",
    "    shuffle=True,\n",
    "    stratify=False,\n",
    ")\n",
    "train = CV.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"0\"\n",
    "train.to_csv(join(proc_data_path, \"train_{}.csv\".format(version)), index=False)\n",
    "test.to_csv(join(proc_data_path, \"test_{}.csv\".format(version)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fold.unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
